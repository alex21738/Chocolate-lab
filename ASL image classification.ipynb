{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf=pd.read_csv('sign_mnist_test.csv')\n",
    "traindf=pd.read_csv('sign_mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.shape, traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.shape, testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([testdf, traindf], axis = 0)\n",
    "# df.reset_index(inplace = True, drop = True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27455, 784), 0     3\n",
       " 1     6\n",
       " 2     2\n",
       " 3     2\n",
       " 4    13\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelstr = traindf['label']\n",
    "traindf.drop(columns =['label'], inplace = True)\n",
    "traindf.shape, labelstr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7172, 784), 0     6\n",
       " 1     5\n",
       " 2    10\n",
       " 3     0\n",
       " 4     3\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelstt = testdf['label']\n",
    "testdf.drop(columns =['label'], inplace = True)\n",
    "testdf.shape, labelstt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# no 9(J) or 25(Z)\n",
    "labelstr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_binrizer = LabelBinarizer()\n",
    "# labels = label_binrizer.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = traindf.values\n",
    "images = np.array([np.reshape(i, (28, 28)) for i in images])\n",
    "images = np.array([i.flatten() for i in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13f9a4d50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelstr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train, image_val, label_train, label_val = train_test_split(images, labelstr, random_state=23, train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 25\n",
    "label_train = keras.utils.to_categorical(label_train, num_classes)\n",
    "label_val = keras.utils.to_categorical(label_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(30, activation='relu', input_shape=(784,)))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(25, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer ='sgd' ,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "histoire = model.fit(image_train,\n",
    "                    label_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(image_val, label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_training_results(histoire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test1 = model.evaluate(imagestest, labelstt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Dense(80, activation='relu', input_shape=(784,)))\n",
    "model2.add(layers.Dense(40, activation='relu'))\n",
    "model2.add(layers.Dense(20, activation='relu'))\n",
    "model2.add(layers.Dense(10, activation='relu'))\n",
    "model2.add(layers.Dense(25, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer ='sgd' ,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model2.fit(image_train,\n",
    "                    label_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(image_val, label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_training_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test2 = model2.evaluate(imagestest, labelstt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Dense(80, activation='relu', input_shape=(784,)))\n",
    "model3.add(layers.Dense(40, activation='relu', kernel_regularizer=regularizers.l2(0.005),))\n",
    "model3.add(layers.Dense(20, activation='relu'))\n",
    "model3.add(layers.Dense(10, activation='relu'))\n",
    "model3.add(layers.Dense(25, activation='softmax'))\n",
    "\n",
    "model3.compile(optimizer ='sgd' ,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history3 = model3.fit(image_train,\n",
    "                    label_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(image_val, label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test3 = model3.evaluate(imagestest, labelstt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train  = np.array([np.reshape(i, (28, 28)) for i in image_train])\n",
    "image_val  = np.array([np.reshape(i, (28, 28)) for i in image_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcnn = models.Sequential()\n",
    "modelcnn.add(layers.Conv1D(32, (3), activation='relu',\n",
    "                        input_shape=(28, 28)))\n",
    "modelcnn.add(layers.MaxPooling1D((2)))\n",
    "\n",
    "modelcnn.add(layers.Conv1D(32, (4), activation='relu'))\n",
    "modelcnn.add(layers.MaxPooling1D((2)))\n",
    "\n",
    "modelcnn.add(layers.Conv1D(64, (3), activation='relu'))\n",
    "modelcnn.add(layers.MaxPooling1D((2)))\n",
    "\n",
    "# modelcnn.add(layers.Conv1D(128, (3), activation='relu', data_format='channels_first'))\n",
    "# modelcnn.add(layers.MaxPooling1D((2)))\n",
    "\n",
    "modelcnn.add(layers.Flatten())\n",
    "modelcnn.add(layers.Dense(64, activation='relu'))\n",
    "modelcnn.add(layers.Dropout(.1))\n",
    "\n",
    "modelcnn.add(layers.Dense(25, activation='softmax'))\n",
    "\n",
    "modelcnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21964 samples, validate on 5491 samples\n",
      "Epoch 1/20\n",
      "21964/21964 [==============================] - 6s 261us/step - loss: 3.1698 - accuracy: 0.0784 - val_loss: 3.0981 - val_accuracy: 0.1100\n",
      "Epoch 2/20\n",
      "21964/21964 [==============================] - 5s 250us/step - loss: 2.8668 - accuracy: 0.1510 - val_loss: 2.4856 - val_accuracy: 0.2358\n",
      "Epoch 3/20\n",
      "21964/21964 [==============================] - 5s 210us/step - loss: 2.3093 - accuracy: 0.2682 - val_loss: 2.0945 - val_accuracy: 0.3488\n",
      "Epoch 4/20\n",
      "21964/21964 [==============================] - 6s 257us/step - loss: 1.8982 - accuracy: 0.3835 - val_loss: 1.6493 - val_accuracy: 0.4935\n",
      "Epoch 5/20\n",
      "21964/21964 [==============================] - 6s 291us/step - loss: 1.5759 - accuracy: 0.4816 - val_loss: 1.3428 - val_accuracy: 0.5749\n",
      "Epoch 6/20\n",
      "21964/21964 [==============================] - 5s 212us/step - loss: 1.2991 - accuracy: 0.5703 - val_loss: 1.0175 - val_accuracy: 0.6740\n",
      "Epoch 7/20\n",
      "21964/21964 [==============================] - 4s 196us/step - loss: 1.0723 - accuracy: 0.6424 - val_loss: 1.0489 - val_accuracy: 0.6476\n",
      "Epoch 8/20\n",
      "21964/21964 [==============================] - 5s 209us/step - loss: 0.8943 - accuracy: 0.6981 - val_loss: 0.7238 - val_accuracy: 0.7611\n",
      "Epoch 9/20\n",
      "21964/21964 [==============================] - 5s 215us/step - loss: 0.7528 - accuracy: 0.7463 - val_loss: 0.6632 - val_accuracy: 0.7826\n",
      "Epoch 10/20\n",
      "21964/21964 [==============================] - 5s 221us/step - loss: 0.6338 - accuracy: 0.7856 - val_loss: 0.7345 - val_accuracy: 0.7285\n",
      "Epoch 11/20\n",
      "21964/21964 [==============================] - 5s 207us/step - loss: 0.5489 - accuracy: 0.8095 - val_loss: 0.5149 - val_accuracy: 0.8228\n",
      "Epoch 12/20\n",
      "21964/21964 [==============================] - 4s 204us/step - loss: 0.4679 - accuracy: 0.8366 - val_loss: 0.3089 - val_accuracy: 0.9069\n",
      "Epoch 13/20\n",
      "21964/21964 [==============================] - 4s 197us/step - loss: 0.4127 - accuracy: 0.8587 - val_loss: 0.2704 - val_accuracy: 0.9211\n",
      "Epoch 14/20\n",
      "21964/21964 [==============================] - 5s 246us/step - loss: 0.3599 - accuracy: 0.8783 - val_loss: 0.2454 - val_accuracy: 0.9261\n",
      "Epoch 15/20\n",
      "21964/21964 [==============================] - 5s 243us/step - loss: 0.3093 - accuracy: 0.8944 - val_loss: 0.2210 - val_accuracy: 0.9343\n",
      "Epoch 16/20\n",
      "21964/21964 [==============================] - 5s 241us/step - loss: 0.2760 - accuracy: 0.9087 - val_loss: 0.1712 - val_accuracy: 0.9521\n",
      "Epoch 17/20\n",
      "21964/21964 [==============================] - 5s 237us/step - loss: 0.2371 - accuracy: 0.9218 - val_loss: 0.1607 - val_accuracy: 0.9528\n",
      "Epoch 18/20\n",
      "21964/21964 [==============================] - 5s 245us/step - loss: 0.2138 - accuracy: 0.9289 - val_loss: 0.1081 - val_accuracy: 0.9761\n",
      "Epoch 19/20\n",
      "21964/21964 [==============================] - 5s 244us/step - loss: 0.1874 - accuracy: 0.9390 - val_loss: 0.1507 - val_accuracy: 0.9534\n",
      "Epoch 20/20\n",
      "21964/21964 [==============================] - 5s 246us/step - loss: 0.1613 - accuracy: 0.9490 - val_loss: 0.1341 - val_accuracy: 0.9554\n"
     ]
    }
   ],
   "source": [
    "results = modelcnn.fit(image_train,\n",
    "                      label_train,\n",
    "                      epochs = 20,\n",
    "                      batch_size=32,\n",
    "                      validation_data=(image_val, label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagestest = testdf.values\n",
    "imagestest = np.array([np.reshape(i, (28, 28)) for i in imagestest])\n",
    "imagestest = np.array([i.flatten() for i in imagestest])\n",
    "imagestest = imagestest/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelstt = keras.utils.to_categorical(labelstt, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagestest  = np.array([np.reshape(i, (28, 28)) for i in imagestest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7172/7172 [==============================] - 1s 86us/step\n"
     ]
    }
   ],
   "source": [
    "results_testcnn = modelcnn.evaluate(imagestest, labelstt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9662367537164748, 0.7745398879051208]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_testcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
